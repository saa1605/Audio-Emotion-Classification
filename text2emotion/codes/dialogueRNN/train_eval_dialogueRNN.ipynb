{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!pip install tensorboardX\nimport time\nimport pickle\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom sklearn.metrics import f1_score, confusion_matrix, accuracy_score,classification_report, precision_recall_fscore_support\nfrom model import BiModel, Model, MaskedNLLLoss\nfrom dataloader import IEMOCAPDataset\nfrom IEMOCAP_utils import *\nnp.random.seed(1234)\n\nDATA_PATH='../../dataset_raw_pkl/iemocap_features/IEMOCAP_features_raw.pkl'\nmodelName='dialogueRnn_2020-04-08 20:40:11.pth'"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "no_cuda=False           # 'does not use GPU'\nlr=0.0001               # 'learning rate'\nl2=0.00001              # 'L2 regularization weight'\nrec_dropout=0.1         # 'rec_dropout rate'\ndropout=0.1             # 'dropout rate'\nbatch_size=30           # 'batch size'\nn_epochs = 20            #'number of epochs'\nclass_weight=True       # 'class weight'\nactive_listener=False   # 'active listener'\nattention='general'     # 'Attention type'\ntensorboard=False       # 'Enables tensorboard log'\nD_a = 100               # concat attention\nD_m = 100\nD_g = 150\nD_p = 150\nD_e = 100\nD_h = 100\nn_classes  = 6\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "train_loader, valid_loader, test_loader =get_IEMOCAP_loaders(DATA_PATH,valid=0.0,batch_size=batch_size,num_workers=2)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialization of Model\ncuda = init_cuda(no_cuda)\n\nmodel = BiModel(D_m, D_g, D_p, D_e, D_h,\n                n_classes=n_classes,\n                listener_state=active_listener,\n                context_attention=attention,\n                dropout_rec=rec_dropout,\n                dropout=dropout)\nif cuda:\n    model.cuda()\n\noptimizer = optim.Adam(model.parameters(),\n                        lr=lr,\n                        weight_decay=l2)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train the model and save in the model directory\n\nif tensorboard:\n    from tensorboardX import SummaryWriter\n\nwriter = SummaryWriter()\n\nbest_loss, best_label, best_pred, best_mask = None, None, None, None\n\nfor e in range(n_epochs):\n    start_time = time.time()\n    train_loss, train_acc, _,_,_,train_fscore,_= train_model(model,tensorboard,train_loader, e, cuda, optimizer)\n    valid_loss, valid_acc, _,_,_,val_fscore,_= eval_model(model,valid_loader,cuda)\n    test_loss, test_acc, test_label, test_pred, test_mask, test_fscore, attentions = eval_model(model,test_loader,cuda)\n\n    if best_loss == None or best_loss > test_loss:\n        best_loss, best_label, best_pred, best_mask, best_attn =\\\n                test_loss, test_label, test_pred, test_mask, attentions\n\n    if tensorboard:\n        writer.add_scalar('test: accuracy/loss',test_acc/test_loss,e)\n        writer.add_scalar('train: accuracy/loss',train_acc/train_loss,e)\n    print('epoch {} train_loss {} train_acc {} train_fscore{}'.format(e+1, train_loss, train_acc, train_fscore)); \n    print('valid_loss {} valid_acc {} val_fscore{}'.format(valid_loss, valid_acc, val_fscore))\n    print('test_loss {} test_acc {} test_fscore {} time {}'.format(test_loss, test_acc, test_fscore, round(time.time()-start_time,2)))\n\nif tensorboard:\n    writer.close()\n\n# Save model \n# save_model(model)\nprint('Test performance..')\nprint('Loss {} accuracy {}'.format(best_loss,\n                                  round(accuracy_score(best_label,best_pred,sample_weight=best_mask)*100,2)))\nprint(classification_report(best_label,best_pred,sample_weight=best_mask,digits=4))\nprint(confusion_matrix(best_label,best_pred,sample_weight=best_mask))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test the trained model\nmodel = load_model(modelName)\ntest_loss, test_acc, test_label, test_pred, test_mask, test_fscore, attentions = eval_model(model, test_loader,cuda)\nprint('Test performance..')\nprint('Loss {} accuracy {}'.format(test_loss,\n                                  round(accuracy_score(test_label,test_pred,sample_weight=test_mask)*100,2)))\nprint(classification_report(test_label,test_pred,sample_weight=test_mask,digits=4))\nprint(confusion_matrix(test_label,test_pred,sample_weight=test_mask))"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
