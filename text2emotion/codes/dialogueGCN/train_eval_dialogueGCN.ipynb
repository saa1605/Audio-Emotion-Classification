{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Requirements\n!pip install torch-geometric\n!pip install torch-sparse\n!pip install torch-scatter"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np, argparse, time, pickle, random\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom model import LSTMModel, GRUModel, DialogRNNModel, DialogueGCNModel\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, precision_recall_fscore_support\nfrom IEMOCAP_utils import *\n\n# We use seed = 100 for reproduction of the results reported in the paper.\nseed = 100\n\nMODEL = ''\nDATA_PATH='../../dataset_raw_pkl/iemocap_features/IEMOCAP_features.pkl'"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "no_cuda=False           #does not use GPU\nbase_model='LSTM'       #base recurrent model, must be one of DialogRNN/LSTM/GRU\ngraph_model=True        #whether to use graph model after recurrent encoding\nnodal_attention=False   #whether to use nodal attention in graph model: Equation 4,5,6 in Paper\nwindowp=10              #context window size for constructing edges in graph model for past utterances')\nwindowf=10              #context window size for constructing edges in graph model for future utterances')\nlr=0.0001               #learning rate\nl2=0.00001              #L2 regularization weight\nrec_dropout=0.1         #rec_dropout rate\ndropout=0.5             #dropout rate\nbatch_size=32           #batch size\nn_epochs=20             #number of epochs\nclass_weight=False      #use class weights\nactive_listener=False   #active listener\nattention='general'     #Attention type in DialogRNN model\ntensorboard=False       #Enables tensorboard log\nn_classes  = 6\nD_m = 100\nD_g = 150\nD_p = 150\nD_e = 100\nD_h = 100\nD_a = 100\ngraph_h = 100"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if graph_model:\n    seed_everything()\n    model = DialogueGCNModel(base_model,\n                                D_m, D_g, D_p, D_e, D_h, D_a, graph_h,\n                                n_speakers=2,\n                                max_seq_len=110,\n                                window_past=windowp,\n                                window_future=windowf,\n                                n_classes=n_classes,\n                                listener_state=active_listener,\n                                context_attention=attention,\n                                dropout=dropout,\n                                nodal_attention=nodal_attention,\n                                no_cuda=no_cuda)\n\n    print ('Graph NN with', base_model, 'as base model.')\n    name = 'Graph'\n\nelse:\n    if base_model == 'DialogRNN':\n        model = DialogRNNModel(D_m, D_g, D_p, D_e, D_h, D_a, \n                                n_classes=n_classes,\n                                listener_state=active_listener,\n                                context_attention=attention,\n                                dropout_rec=rec_dropout,\n                                dropout=dropout)\n\n        print ('Basic Dialog RNN Model.')\n\n\n    elif base_model == 'GRU':\n        model = GRUModel(D_m, D_e, D_h, \n                            n_classes=n_classes, \n                            dropout=dropout)\n\n        print ('Basic GRU Model.')\n\n\n    elif base_model == 'LSTM':\n        model = LSTMModel(D_m, D_e, D_h, \n                            n_classes=n_classes, \n                            dropout=dropout)\n\n        print ('Basic LSTM Model.')\n\n    else:\n        print ('Base model must be one of DialogRNN/LSTM/GRU/Transformer')\n        raise NotImplementedError\n\n    name = 'Base'"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "train_loader, valid_loader, test_loader = get_IEMOCAP_loaders(path=DATA_PATH,batch_size=batch_size,valid=0.0,num_workers=0)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if tensorboard:\n    from tensorboardX import SummaryWriter\n    writer = SummaryWriter()\n\n\ncuda = init_cuda(no_cuda)\n\nif cuda:\n    model.cuda()\n\noptimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=l2)\n\nbest_fscore, best_loss, best_label, best_pred, best_mask = None, None, None, None, None\nall_fscore, all_acc, all_loss = [], [], []\n\nfor e in range(n_epochs):\n    start_time = time.time()\n\n    if graph_model:\n        train_loss, train_acc, _, _, train_fscore, _, _, _, _, _ = train_or_eval_graph_model(cuda,model, train_loader, e, optimizer, True,tensorboard)\n        valid_loss, valid_acc, _, _, valid_fscore, _, _, _, _, _ = train_or_eval_graph_model(cuda,model, valid_loader, e)\n        test_loss, test_acc, test_label, test_pred, test_fscore, _, _, _, _, _ = train_or_eval_graph_model(cuda , model,test_loader, e)\n        all_fscore.append(test_fscore)\n\n        if best_loss == None or best_loss > test_loss:\n            best_loss, best_label, best_pred =\\\n                    test_loss, test_label, test_pred\n        # torch.save({'model_state_dict': model.state_dict()}, path + name + base_model + '_' + str(e) + '.pkl')\n\n    else:\n        train_loss, train_acc, _, _, _, train_fscore, _ = train_or_eval_model(cuda,model, train_loader, e, optimizer, True,tensorboard)\n        valid_loss, valid_acc, _, _, _, valid_fscore, _ = train_or_eval_model(cuda ,model, valid_loader,e)\n        test_loss, test_acc, test_label, test_pred, test_mask, test_fscore, attentions = train_or_eval_model(cuda,model, test_loader, e)\n        all_fscore.append(test_fscore)\n        \n        if best_loss == None or best_loss > test_loss:\n            best_loss, best_label, best_pred, best_mask, best_attn =\\\n                    test_loss, test_label, test_pred, test_mask, attentions\n        # torch.save({'model_state_dict': model.state_dict()}, path + name + base_model + '_' + str(e) + '.pkl')\n    \n    if tensorboard:\n        writer.add_scalar('test: accuracy/loss', test_acc/test_loss, e)\n        writer.add_scalar('train: accuracy/loss', train_acc/train_loss, e)\n\n    print('epoch {} train_loss {} train_acc {} train_fscore{}'.format(e+1, train_loss, train_acc, train_fscore))\n    print('valid_loss {} valid_acc {} val_fscore{}'.format(valid_loss, valid_acc, valid_fscore))\n    print('test_loss {} test_acc {} test_fscore {} time {}'.format(test_loss, test_acc, test_fscore, round(time.time()-start_time,2)))\n\n\n\nif tensorboard:\n    writer.close()\n\nsave_model(model,optimizer,name,base_model)\nprint('Test performance..')\nprint ('F-Score:', max(all_fscore))\n\nif graph_model:\n  print('Graph Model Accuracy')\nelse:\n  print('Base Model Accuracy')\nprint('Loss {} accuracy {}'.format(best_loss,round(accuracy_score(best_label,best_pred,sample_weight=best_mask)*100,2)))\nprint(classification_report(best_label,best_pred,sample_weight=best_mask,digits=4))\nprint(confusion_matrix(best_label,best_pred,sample_weight=best_mask))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "model = load_model(MODEL)\nprint('Test performance..')\nif graph_model:\n    print('Graph Model Accuracy')\n    test_loss, test_acc, test_label, test_pred, test_fscore, _, _, _, _, _ = train_or_eval_graph_model(cuda , model,test_loader, e)\n\nelse:\n    print('Base Model Accuracy')\n    test_loss, test_acc, test_label, test_pred, test_mask, test_fscore, attentions = train_or_eval_model(cuda,model, test_loader, e)\n\nprint('Loss {} accuracy {}'.format(test_loss,round(accuracy_score(test_label,test_pred,sample_weight=test_mask)*100,2)))\nprint(classification_report(test_label,test_pred,sample_weight=test_mask,digits=4))\nprint(confusion_matrix(test_label,test_pred,sample_weight=test_mask))"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
